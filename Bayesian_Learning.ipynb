{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sime1/notebooks/blob/master/Bayesian_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QLfKg9fLvez",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes - 20 newsgroups dataset \n",
        "\n",
        "In questo notebook applico i diversi metodi *Naive Bayes* forniti da `sklearn` al dataset [20 newsgroups](http://qwone.com/~jason/20Newsgroups/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL_WczZoLuxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "train_ds = fetch_20newsgroups(subset='train')\n",
        "test_ds = fetch_20newsgroups(subset='test')\n",
        "\n",
        "vectorizer.fit(train_ds.data)\n",
        "\n",
        "X_train, y_train = vectorizer.transform(train_ds.data), train_ds.target\n",
        "X_test, y_test = vectorizer.transform(test_ds.data), test_ds.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPef8BHn6zi",
        "colab_type": "text"
      },
      "source": [
        "Come è possibile vedere dal codice, ho deciso di utilizzare `TfidfVectorizer` per trasformare i testi dei messaggi nel dataset in vettori di feature, in modo da poterli utilizzare coi metodi di `sklearn`.\n",
        "\n",
        "Ho utilizzato questo metodo invece che `CountVectorizer` (quello utilizzato dalla funzione `fetch_20newsgroups_vectorized`) perché ho notato che da risultati migliori."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_0D1gb3RQ8x",
        "colab_type": "text"
      },
      "source": [
        "## Multinomial NB\n",
        "\n",
        "Questo metodo implementa l'algoritmo NB per dati che seguono una [distribuzione multinomiale](https://en.wikipedia.org/wiki/Multinomial_distribution). In particolare, è una delle varianti dell'algoritmo che viene applicata calssicamente a task di classificazione testuale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RDfGHhMSK4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd78d866-b32a-43af-9429-ef282bd7877b"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "params = {\n",
        "    # 1.0e-10 instead of 0 to avoid getting a warning\n",
        "    'alpha': np.linspace(1.0e-10, 2.0, 20)\n",
        "}\n",
        "\n",
        "model = MultinomialNB()\n",
        "sel = GridSearchCV(model, params, cv=5)\n",
        "sel.fit(X_train, y_train)\n",
        "mnb_model = sel.best_estimator_\n",
        "mnb_model.score(X_test, y_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8255443441317047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxpx7F1HS65s",
        "colab_type": "text"
      },
      "source": [
        "# Complement NB\n",
        "\n",
        "Questo metodo è un adattamento del *Multinomial NB* che funziona particolarmente bene con dataset non equilibrati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdfDj_WpTqfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83aa074b-0d38-42f8-b1f6-524ba18a6bc9"
      },
      "source": [
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "params = {\n",
        "    # 1.0e-10 instead of 0 to avoid getting a warning\n",
        "    'alpha': np.linspace(1.0e-10, 2.0, 20),\n",
        "    'norm': [True, False]\n",
        "}\n",
        "\n",
        "model = ComplementNB()\n",
        "sel = GridSearchCV(model, params, cv=5)\n",
        "sel.fit(X_train, y_train)\n",
        "cnb_model = sel.best_estimator_\n",
        "cnb_model.score(X_test, y_test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8315188528943176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjC4iD5Udacr",
        "colab_type": "text"
      },
      "source": [
        "## Bernoulli NB\n",
        "\n",
        "Questo metodo implementa NB per dati che hanno una distribuzione di Bernoulli multivariata; questo significa che il metodo permette di avere più features, ma assume che ognuna di esse sia binaria "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeQNeqEChSjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d336f760-646a-4e7c-d9c9-3d2f67a5ec06"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "params = {\n",
        "    'alpha': np.linspace(1.0e-10, 2.0, 10),\n",
        "    'binarize': np.linspace(0.0, 1.0, 4)\n",
        "}\n",
        "\n",
        "model = BernoulliNB()\n",
        "sel = GridSearchCV(model, params, cv=5)\n",
        "sel.fit(X_train, y_train)\n",
        "bnb_model = sel.best_estimator_\n",
        "bnb_model.score(X_test, y_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7792087095061073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiKF5S1tbV6A",
        "colab_type": "text"
      },
      "source": [
        "## Confronto risultati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xccPt5ySbgSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "43dce96f-56ab-437c-8b28-2a5e26bfcd56"
      },
      "source": [
        "print('Multinomial')\n",
        "print(f'\\tscore: {mnb_model.score(X_test, y_test)}')\n",
        "print('\\tparameters:')\n",
        "print(f'\\t\\talpha:{mnb_model.alpha}')\n",
        "\n",
        "print('Complement\\n')\n",
        "print(f'\\tscore: {cnb_model.score(X_test, y_test)}')\n",
        "print('\\tparameters:')\n",
        "print(f'\\t\\talpha:{cnb_model.alpha}')\n",
        "print(f'\\t\\tnorm:{cnb_model.norm}')\n",
        "\n",
        "print('Bernoulli\\n')\n",
        "print(f'\\tscore: {bnb_model.score(X_test, y_test)}')\n",
        "print('\\tparameters:')\n",
        "print(f'\\t\\talpha:{bnb_model.alpha}')\n",
        "print(f'\\t\\tbinarize:{bnb_model.binarize}')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial\n",
            "\tscore: 0.8255443441317047\n",
            "\tparameters:\n",
            "\t\talpha:0.10526315798947368\n",
            "Complement\n",
            "\n",
            "\tscore: 0.8315188528943176\n",
            "\tparameters:\n",
            "\t\talpha:0.10526315798947368\n",
            "\t\tnorm:False\n",
            "Bernoulli\n",
            "\n",
            "\tscore: 0.7792087095061073\n",
            "\tparameters:\n",
            "\t\talpha:1e-10\n",
            "\t\tbinarize:0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z8RIUP3cuDF",
        "colab_type": "text"
      },
      "source": [
        "### Note\n",
        "\n",
        "* Non ho utilizzato nè *Gaussian NB* nè *Categorical NB* in quanto la loro implementazione in `sklearn` richiede dati in formato denso, e provare a trasformare i dati da matrice sparsa a densa richiede più RAM di quanta resa disponibile da Colab."
      ]
    }
  ]
}